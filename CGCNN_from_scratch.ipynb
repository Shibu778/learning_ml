{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN7r45HJG/ZdQIkWMxs7wF0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shibu778/learning_ml/blob/main/CGCNN_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CGCNN from Scratch"
      ],
      "metadata": {
        "id": "A_Rorm0DNSrk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Crystal Graph Convolutional Neural Networks (CGCNN) is a machine learning framework that predicts material properties from crystal structures using graph neural networks. CGCNN framework directly learns about the materials properties from the connection between the atoms providing a universal and interpretable representation of crystalline materials. The main idea in this approach is to represent the crystal structure by a crystal graph that encodes both atomic information and bonding interactions between atoms, and then build a convolutional neural network on top of the graph to automatically extract representations that are optimum for predicting target properties by training with DFT calculated data."
      ],
      "metadata": {
        "id": "45sdqhoYNW1o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A crystal graph $G$ is an undirected graph which is defined by nodes representing atoms and edges representing connection between atoms in a crystal. Unlike a normal graph it allows multiple edges between smae pair of end nodes to account for periodicity. Each node is represented by a feature vector $\\textbf{v}_i$, encoding the property of the atom corresponding to node $i$. Similarly, each edge $(i, j)_k$ is represented by a feutre vector $\\textbf{u}_{(i,j)_k}$, corresponding to the $k^{th}$ bond connecting atom $i$ and atom $j$."
      ],
      "metadata": {
        "id": "C8OnhluTSPrQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The convolutional neural network built on top of the crystal graph consist of two major components: convolutional layers and pooling layers. The convolutional layers iteratively update the atom feature vector $\\textbf{v}_i$ by convolution with surrounding atoms and bonds with a nonlinear graph convolution function,\n",
        "\n",
        "$$\\textbf{v}_i^{t+1} = Conv\\left(\\textbf{v}_i^{(t)}, \\textbf{v}_j^{(t)}, \\textbf{u}_{(i,j)_k}\\right), (i, j)_k ~ ùùê ~ G$$."
      ],
      "metadata": {
        "id": "NwNpcfOhTgLj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After $R$ convolutions, the network automatically learns the feature vector $\\textbf{v}_i^{(R)}$ for each atom by iteratively including its surrounding environment. The pooling layer is then used for producing an overall feature vector $\\textbf{v}_c$ for the crystal, which can be represented by a pooling function,\n",
        "\n",
        "$$\\textbf{v}_c = Pool\\left( \\textbf{v}_0^{(0)}, \\textbf{v}_N^{(0)}, ..., \\textbf{v}_N^{(0)}, ..., \\textbf{v}_N^{(R)} \\right)$$\n",
        "\n",
        "that satisfies permutational invariance with respect to atom indexing and size invariance with respect to unit cell choice. A simple choice of pooling function can be normalized summation."
      ],
      "metadata": {
        "id": "IOmYubrxWBVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In addition to convolutional and pooling layers, two fully connected hidden layers with the depths of $L_1$ and $L_2$ are added to capture the complex mapping between crystal structure and property. Finally, an output layer is used to connect the $L_2$ hidden layer to predict the target property $\\hat{y}$."
      ],
      "metadata": {
        "id": "Q8irt2jkXxQB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training is performed by minimizing the difference between the predicted property $\\hat{y}$ and the DFT calculated property $y$, defined by a cost function $J(y, \\hat{y})$."
      ],
      "metadata": {
        "id": "sJaMrFTFZid4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The whole CGCNN can be considered as a function $f$ parametrized by weights $\\textbf{W}$ that maps a crystal $C$ to the target property $\\hat{y}$. By using backpropagation and stachastic gradient descent (SGD), following optimization problem can be solved by iteratively updating the weights with DFT calculated data:\n",
        "$$\\min_{\\textbf{W}} J(y, f(C;\\textbf{W}))$$\n",
        "the learned weights can then be used to predict materials properies and provide chemical insights for future materials design."
      ],
      "metadata": {
        "id": "LHSUvnRiZ5VE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XjbDxkCnbGk8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Cn6NAYCNOtK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "1. https://github.com/txie-93/cgcnn\n",
        "2. https://journals.aps.org/prl/pdf/10.1103/PhysRevLett.120.145301\n",
        "\n",
        "Note: Please note that I am trying to learn CGCNN by breaking it down into small pieces here. Text and code presented here may be copied from the above resources. This is only for learning and practice purpose."
      ],
      "metadata": {
        "id": "QNxW1Bo2O75c"
      }
    }
  ]
}